{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sergio-Ibarra-1795/w_efficiency_related/blob/main/Copy_of_Chatbot_with_custom_knowledge_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwaLK4kD1Uar"
      },
      "source": [
        "#Introduction\n",
        "\n",
        "This notebook has all the code you need to create your own chatbot with custom knowledge base using GPT-3. \n",
        "\n",
        "Follow the instructions for each steps and then run the code sample. In order to run the code, you need to press \"play\" button near each code sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD4Qzglp3J-h"
      },
      "source": [
        "#Download the data for your custom knowledge base\n",
        "For the demonstration purposes we are going to use ----- as our knowledge base. You can download them to your local folder from the github repository by running the code below.\n",
        "Alternatively, you can put your own custom data into the local folder. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cCyU-vV5Yb0",
        "outputId": "3541b6ac-ae15-4ea7-8fc1-c710820d26a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'context_data'...\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/irina1nik/context_data.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiUyHP4T2g5F"
      },
      "source": [
        "# Install the dependicies\n",
        "Run the code below to install the depencies we need for our functions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Introduction\n",
        "You can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a community-maintained library.\n",
        "\n",
        "To install the official Python bindings, run the following command:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\python310\\lib\\site-packages (0.27.2)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: aiohttp in c:\\python310\\lib\\site-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\python310\\lib\\site-packages (from openai) (2.28.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai) (1.26.12)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python310\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python310\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python310\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python310\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python310\\lib\\site-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\sergi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6LL4rxT6_W7h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index in c:\\python310\\lib\\site-packages (0.4.28)Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: dataclasses_json in c:\\python310\\lib\\site-packages (from llama-index) (0.5.7)\n",
            "Requirement already satisfied: langchain in c:\\python310\\lib\\site-packages (from llama-index) (0.0.111)\n",
            "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from llama-index) (1.23.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\python310\\lib\\site-packages (from llama-index) (8.2.2)\n",
            "Requirement already satisfied: openai>=0.26.4 in c:\\python310\\lib\\site-packages (from llama-index) (0.27.2)\n",
            "Requirement already satisfied: pandas in c:\\python310\\lib\\site-packages (from llama-index) (1.5.0)\n",
            "Requirement already satisfied: tiktoken in c:\\python310\\lib\\site-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\python310\\lib\\site-packages (from openai>=0.26.4->llama-index) (2.28.1)\n",
            "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in c:\\python310\\lib\\site-packages (from openai>=0.26.4->llama-index) (3.8.4)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\python310\\lib\\site-packages (from dataclasses_json->llama-index) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\python310\\lib\\site-packages (from dataclasses_json->llama-index) (0.8.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\python310\\lib\\site-packages (from dataclasses_json->llama-index) (3.19.0)\n",
            "Requirement already satisfied: pydantic<2,>=1 in c:\\python310\\lib\\site-packages (from langchain->llama-index) (1.10.6)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in c:\\python310\\lib\\site-packages (from langchain->llama-index) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\python310\\lib\\site-packages (from langchain->llama-index) (1.4.46)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas->llama-index) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\python310\\lib\\site-packages (from tiktoken->llama-index) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (1.8.2)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\python310\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses_json->llama-index) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python310\\lib\\site-packages (from pydantic<2,>=1->langchain->llama-index) (4.4.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (1.26.12)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\python310\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain->llama-index) (2.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python310\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses_json->llama-index) (1.0.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\sergi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai>=0.26.4->llama-index) (0.4.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses_json->llama-index) (3.0.9)\n",
            "Requirement already satisfied: langchain in c:\\python310\\lib\\site-packages (0.0.111)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\python310\\lib\\site-packages (from langchain) (1.23.3)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in c:\\python310\\lib\\site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\python310\\lib\\site-packages (from langchain) (1.4.46)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\python310\\lib\\site-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python310\\lib\\site-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: pydantic<2,>=1 in c:\\python310\\lib\\site-packages (from langchain) (1.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\python310\\lib\\site-packages (from langchain) (2.28.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python310\\lib\\site-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\python310\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\python310\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\python310\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python310\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.12)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\python310\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\python310\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python310\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.9)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index\n",
        "%pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbuYetOy25eM"
      },
      "source": [
        "# Define the functions\n",
        "The following code defines the functions we need to construct the index and query it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UelAqQgk_yIt"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
        "from langchain import OpenAI\n",
        "import sys\n",
        "import os\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def construct_index(directory_path):\n",
        "    # set maximum input size\n",
        "    max_input_size = 4096\n",
        "    # set number of output tokens\n",
        "    num_outputs = 2000\n",
        "    # set maximum chunk overlap\n",
        "    max_chunk_overlap = 20\n",
        "    # set chunk size limit\n",
        "    chunk_size_limit = 600 \n",
        "\n",
        "    # define LLM\n",
        "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n",
        "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
        " \n",
        "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
        "    \n",
        "    index = GPTSimpleVectorIndex(\n",
        "        documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
        "    )\n",
        "\n",
        "    index.save_to_disk('index.json')\n",
        "\n",
        "    return index\n",
        "\n",
        "def ask_ai():\n",
        "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
        "    while True: \n",
        "        query = input(\"What do you want to ask? \")\n",
        "        response = index.query(query, response_mode=\"compact\")\n",
        "        display(Markdown(f\"Response: <b>{response.response}</b>\"))\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz1jp33jGumu"
      },
      "source": [
        "# Set OpenAI API Key\n",
        "You need an OPENAI API key to be able to run this code.\n",
        "\n",
        "If you don't have one yet, get it by [signing up](https://platform.openai.com/overview). Then click your account icon on the top right of the screen and select \"View API Keys\". Create an API key.\n",
        "\n",
        "Then run the code below and paste your API key into the text input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RoJHE4fsAT3w"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVrddlAL4I_v"
      },
      "source": [
        "#Construct an index\n",
        "Now we are ready to construct the index. This will take every file in the folder 'data', split it into chunks, and embed it with OpenAI's embeddings API.\n",
        "\n",
        "**Notice:** running this code will cost you credits on your OpenAPI account ($0.02 for every 1,000 tokens). If you've just set up your account, the free credits that you have should be more than enough for this experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4.28\n"
          ]
        }
      ],
      "source": [
        "import llama_index\n",
        "print(llama_index.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index in c:\\python310\\lib\\site-packages (0.4.28)Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: dataclasses_json in c:\\python310\\lib\\site-packages (from llama-index) (0.5.7)\n",
            "Requirement already satisfied: langchain in c:\\python310\\lib\\site-packages (from llama-index) (0.0.111)\n",
            "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from llama-index) (1.23.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\python310\\lib\\site-packages (from llama-index) (8.2.2)\n",
            "Requirement already satisfied: openai>=0.26.4 in c:\\python310\\lib\\site-packages (from llama-index) (0.27.2)\n",
            "Requirement already satisfied: pandas in c:\\python310\\lib\\site-packages (from llama-index) (1.5.0)\n",
            "Requirement already satisfied: tiktoken in c:\\python310\\lib\\site-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\python310\\lib\\site-packages (from openai>=0.26.4->llama-index) (2.28.1)\n",
            "Requirement already satisfied: aiohttp in c:\\python310\\lib\\site-packages (from openai>=0.26.4->llama-index) (3.8.4)\n",
            "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\python310\\lib\\site-packages (from dataclasses_json->llama-index) (1.5.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\python310\\lib\\site-packages (from dataclasses_json->llama-index) (3.19.0)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\python310\\lib\\site-packages (from dataclasses_json->llama-index) (0.8.0)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in c:\\python310\\lib\\site-packages (from langchain->llama-index) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\python310\\lib\\site-packages (from langchain->llama-index) (1.4.46)\n",
            "Requirement already satisfied: pydantic<2,>=1 in c:\\python310\\lib\\site-packages (from langchain->llama-index) (1.10.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas->llama-index) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\python310\\lib\\site-packages (from tiktoken->llama-index) (2022.10.31)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python310\\lib\\site-packages (from aiohttp->openai>=0.26.4->llama-index) (2.1.1)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\python310\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses_json->llama-index) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python310\\lib\\site-packages (from pydantic<2,>=1->langchain->llama-index) (4.4.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (1.26.12)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\python310\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain->llama-index) (2.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python310\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses_json->llama-index) (1.0.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\sergi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai>=0.26.4->llama-index) (0.4.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses_json->llama-index) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade llama-index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kCYTE2EqBB7O"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'construct_index' from 'llama_index' (c:\\Python310\\lib\\site-packages\\llama_index\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m \u001b[39mimport\u001b[39;00m construct_index\n\u001b[0;32m      2\u001b[0m construct_index(\u001b[39m\"\u001b[39m\u001b[39mcontext_data/data\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'construct_index' from 'llama_index' (c:\\Python310\\lib\\site-packages\\llama_index\\__init__.py)"
          ]
        }
      ],
      "source": [
        "\n",
        "from llama_index import construct_index\n",
        "construct_index(\"context_data/data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'construct_index' from 'llama_index.utils' (c:\\Python310\\lib\\site-packages\\llama_index\\utils.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m construct_index\n\u001b[0;32m      2\u001b[0m construct_index(\u001b[39m\"\u001b[39m\u001b[39mcontext_data/data\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'construct_index' from 'llama_index.utils' (c:\\Python310\\lib\\site-packages\\llama_index\\utils.py)"
          ]
        }
      ],
      "source": [
        "from llama_index.utils import construct_index\n",
        "construct_index(\"context_data/data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "attempted relative import with no known parent package",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39masync_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m construct_index\n\u001b[0;32m      3\u001b[0m construct_index(\u001b[39m\"\u001b[39m\u001b[39mcontext_data/data\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
          ]
        }
      ],
      "source": [
        "from .async_utils import construct_index\n",
        "\n",
        "construct_index(\"context_data/data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipJ_gYxN5cWh"
      },
      "source": [
        "#Ask questions\n",
        "It's time to have fun and test our AI. Run the function that queries GPT and type your question into the input. \n",
        "\n",
        "If you've used the provided example data for your custom knowledge base, here are a few questions that you can ask:\n",
        "1. Why people cook at home? Make classification\n",
        "2. Make classification about what frustrates people about cooking?\n",
        "3. Brainstorm marketing campaign ideas for an air fryer that would appeal people that cook at home\n",
        "4. Which kitchen appliences people use most often?\n",
        "5. What people like about cooking at home?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s_uwsPGEIGsb"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'index.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ask_ai()\n",
            "Cell \u001b[1;32mIn[19], line 32\u001b[0m, in \u001b[0;36mask_ai\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mask_ai\u001b[39m():\n\u001b[1;32m---> 32\u001b[0m     index \u001b[39m=\u001b[39m GPTSimpleVectorIndex\u001b[39m.\u001b[39;49mload_from_disk(\u001b[39m'\u001b[39;49m\u001b[39mindex.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     33\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m: \n\u001b[0;32m     34\u001b[0m         query \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWhat do you want to ask? \u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\llama_index\\indices\\base.py:562\u001b[0m, in \u001b[0;36mBaseGPTIndex.load_from_disk\u001b[1;34m(cls, save_path, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    543\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_disk\u001b[39m(\u001b[39mcls\u001b[39m, save_path: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mBaseGPTIndex\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    544\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load index from disk.\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \n\u001b[0;32m    546\u001b[0m \u001b[39m    This method loads the index from a JSON file stored on disk. The index data\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    560\u001b[0m \n\u001b[0;32m    561\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 562\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(save_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    563\u001b[0m         file_contents \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m    564\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mload_from_string(file_contents, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'index.json'"
          ]
        }
      ],
      "source": [
        "ask_ai()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
